{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HX9ItY17dIaH"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install corus\n",
        "!pip install gensim\n",
        "!pip install navec\n",
        "!pip install pymorphy3\n",
        "!python -m spacy download ru_core_news_sm\n",
        "\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import itertools\n",
        "import re\n",
        "import spacy\n",
        "import gensim\n",
        "import urllib.request\n",
        "\n",
        "from corus import load_lenta\n",
        "from navec import Navec\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
        "from pymorphy3 import MorphAnalyzer\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, make_scorer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "np.random.seed(998)\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Qt4rZO7X-7V"
      },
      "source": [
        "## Загрузка и предобработка данных\n",
        "\n",
        "Эта часть во многом аналогична первому\n",
        " ДЗ: загружаем датасет, по сгенерированным рандомным 10 тысячам индексов выбираем 10 тысяч строк (т.к. со 100 возникали проблемы с колабом), предобрабатываем текст с помощью spacy, делим на трейн/валидацию/тест.\n",
        "\n",
        "Хотелось бы взять 100к с тем же рандом сидом и посмотреть как на тех же текстах одна и та же логистическая регрессия работает с разными признаками (из векторайзеров и из эмбеддингов), но сейчас я могу работать только в колабе, а он на 100к иногда очень неприятно отключается"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "E3cHT-sqXdQ1",
        "outputId": "acc2ab3c-7bba-4072-e982-561b8b451f7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-14 06:23:43--  https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250314%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250314T062343Z&X-Amz-Expires=300&X-Amz-Signature=55f83137f7ee039bbbd3d34d85cecc715276e34071717cd5c819034c5c1417cc&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-03-14 06:23:43--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250314%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250314T062343Z&X-Amz-Expires=300&X-Amz-Signature=55f83137f7ee039bbbd3d34d85cecc715276e34071717cd5c819034c5c1417cc&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 527373240 (503M) [application/octet-stream]\n",
            "Saving to: ‘lenta-ru-news.csv.gz’\n",
            "\n",
            "lenta-ru-news.csv.g 100%[===================>] 502.94M  90.4MB/s    in 5.2s    \n",
            "\n",
            "2025-03-14 06:23:49 (97.2 MB/s) - ‘lenta-ru-news.csv.gz’ saved [527373240/527373240]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jWZRrca2YGyw"
      },
      "outputs": [],
      "source": [
        "path = 'lenta-ru-news.csv.gz'\n",
        "records = load_lenta(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlULya7SYKar",
        "outputId": "497ea7ee-5aac-4cba-a45b-adb65a7e713d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "739351"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# длина оригинального датасета через копию генератора\n",
        "records, records_copy = itertools.tee(records)\n",
        "total_len = sum(1 for _ in records_copy)\n",
        "total_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Jw_gxLNNYQzI"
      },
      "outputs": [],
      "source": [
        "sample_size = 10000\n",
        "\n",
        "random_idx = np.random.choice(total_len, size=sample_size, replace=False)\n",
        "sampled_records = []\n",
        "for i, record in enumerate(records):\n",
        "    if i in random_idx:\n",
        "        sampled_records.append((i, record))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tduI3ctZYQwZ",
        "outputId": "73633c2b-4281-4c1f-ca32-4aacdd21e813"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   index_new                                              title  \\\n",
            "0        143  Обвиненного в госизмене ученого наказали за от...   \n",
            "1        222  Лукашенко объяснил ненужность российской авиаб...   \n",
            "2        293  Кадыров попросил ему не мешать и еще больше денег   \n",
            "3        312  Хваставшийся в Instagram дорогой одеждой батюш...   \n",
            "4        325  Венгры взбунтовались против рабского труда и у...   \n",
            "\n",
            "                                                text        topic  \n",
            "0  Заключенному под стражу по делу о госизмене ро...       Россия  \n",
            "1  Поднятие вопроса о возможности создания в Бело...  Бывший СССР  \n",
            "2  Глава Чеченской республики Рамзан Кадыров отре...    Экономика  \n",
            "3  Представители Тверской епархии сочли поведение...     Ценности  \n",
            "4  В Венгрии сотни людей вышли на акции протеста ...          Мир  \n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame({\n",
        "    'index_new': [i[0] for i in sampled_records],\n",
        "    'title': [i[1].title for i in sampled_records],\n",
        "    'text': [i[1].text for i in sampled_records],\n",
        "    'topic': [i[1].topic for i in sampled_records]\n",
        "})\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "XW__jJirYQs8",
        "outputId": "3e9d1bb9-0d30-46d5-8611-fc55200be9ae"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array(['Россия', 'Бывший СССР', 'Экономика', 'Ценности', 'Мир',\n",
              "       'Интернет и СМИ', 'Спорт', 'Силовые структуры', 'Из жизни', 'Дом',\n",
              "       'Наука и техника', 'Путешествия', 'Культура', '69-я параллель',\n",
              "       'Крым', 'Бизнес', 'Культпросвет ', 'Легпром', ''], dtype=object)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(df.topic.unique())\n",
        "# display(df[df.topic == ''].sample(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "CWaoIvkBaowG",
        "outputId": "845b21ed-e883-4dac-8c8f-57a102b98b6b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "topic\n",
              "Россия               2251\n",
              "Мир                  1862\n",
              "Экономика            1098\n",
              "Спорт                 848\n",
              "Бывший СССР           745\n",
              "Культура              695\n",
              "Наука и техника       694\n",
              "Интернет и СМИ        582\n",
              "Из жизни              380\n",
              "Дом                   263\n",
              "Силовые структуры     262\n",
              "Ценности              114\n",
              "Бизнес                 92\n",
              "Путешествия            87\n",
              "69-я параллель         12\n",
              "Другое                 12\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Россия</th>\n",
              "      <td>2251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Мир</th>\n",
              "      <td>1862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Экономика</th>\n",
              "      <td>1098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Спорт</th>\n",
              "      <td>848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Бывший СССР</th>\n",
              "      <td>745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Культура</th>\n",
              "      <td>695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Наука и техника</th>\n",
              "      <td>694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Интернет и СМИ</th>\n",
              "      <td>582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Из жизни</th>\n",
              "      <td>380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Дом</th>\n",
              "      <td>263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Силовые структуры</th>\n",
              "      <td>262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ценности</th>\n",
              "      <td>114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Бизнес</th>\n",
              "      <td>92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Путешествия</th>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69-я параллель</th>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Другое</th>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# есть пустая категория, судя по всему с неклассифицированными статьями, их всего 27\n",
        "# удаляем их\n",
        "# и есть категории с 6 и 1 значениями, объединю эти категории в класс Другое\n",
        "df = df[df.topic != '']\n",
        "df.loc[(df['topic'] == 'Культпросвет ') | (df['topic'] == 'Легпром') | (df['topic'] == 'Крым'),'topic'] = 'Другое'\n",
        "\n",
        "# классы очень несбалансированные, но т.к. это был случайный выбор + доля достаточно большая считаем что выборка репрезентативная\n",
        "display(df.topic.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iFSPZIggaorA"
      },
      "outputs": [],
      "source": [
        "df['text'] = df['text'].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8RCdndNNax6R"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"ru_core_news_sm\", disable=[\"parser\", \"ner\"])\n",
        "russian_stopwords = set(stopwords.words('russian'))\n",
        "\n",
        "def clean_text_spacy(text):\n",
        "    doc = nlp(text)\n",
        "    lemmas = [\n",
        "        token.lemma_\n",
        "        for token in doc\n",
        "        if token.is_alpha and token.text not in russian_stopwords\n",
        "    ]\n",
        "    return lemmas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IxELplgqax3q"
      },
      "outputs": [],
      "source": [
        "X = df['text'].apply(clean_text_spacy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sE5ol89Yax1M"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "y = le.fit_transform(df['topic'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WWjWFTRJa7jm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "762f79bc-0412-44a9-ed53-de6e8ec3ec02"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9997"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "len(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "P146QT6Fa7s1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9313b241-e75d-454f-ff19-b021a6575354"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9997"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "len(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "06k4qs3ya7_1"
      },
      "outputs": [],
      "source": [
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.4, stratify=y, random_state=998\n",
        ")\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=998\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Ylt2IJwWWkaV"
      },
      "outputs": [],
      "source": [
        "# делаем доп.сет параметров для русвек-а, проверяем что теги те же, которые есть в модели\n",
        "def add_pos_tags(docs):\n",
        "    pos_docs = []\n",
        "    for doc in docs:\n",
        "        text = \" \".join(doc)\n",
        "        spacy_doc = nlp(text)\n",
        "        pos_docs.append([f\"{word.text}_{word.pos_}\" for word in spacy_doc])\n",
        "    return pos_docs\n",
        "\n",
        "X_train_pos = add_pos_tags(X_train)\n",
        "X_val_pos = add_pos_tags(X_val)\n",
        "X_test_pos = add_pos_tags(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-DXdYWgkZnC2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f0209bb-23c9-44d4-abdf-a863f85cd4ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5998 1999 2000\n",
            "5998 1999 2000\n"
          ]
        }
      ],
      "source": [
        "print(len(X_train), len(X_val), len(X_test))\n",
        "print(len(X_train_pos), len(X_val_pos), len(X_test_pos))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "f4OWmJY5_6LG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44bd0692-59a9-48d9-84a5-743f4a3e7510"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['япония_NOUN',\n",
              " 'воссоздать_VERB',\n",
              " 'снег_NOUN',\n",
              " 'имперский_ADJ',\n",
              " 'штурмовик_NOUN',\n",
              " 'киносаги_NOUN',\n",
              " 'звёздный_ADJ',\n",
              " 'война_NOUN',\n",
              " 'сообщать_VERB',\n",
              " 'the_X',\n",
              " 'daily_X',\n",
              " 'mirror_X',\n",
              " 'скульптура_NOUN',\n",
              " 'высота_NOUN',\n",
              " 'около_ADP',\n",
              " 'девять_NUM',\n",
              " 'метр_NOUN',\n",
              " 'создать_VERB',\n",
              " 'снежный_ADJ',\n",
              " 'фестиваль_NOUN',\n",
              " 'саппоро_X',\n",
              " 'центр_NOUN',\n",
              " 'композиция_NOUN',\n",
              " 'расположен_ADJ',\n",
              " 'дарт_PROPN',\n",
              " 'вейдер_PROPN',\n",
              " 'окружение_NOUN',\n",
              " 'три_NUM',\n",
              " 'штурмовик_NOUN',\n",
              " 'задний_ADJ',\n",
              " 'план_NOUN',\n",
              " 'разместить_VERB',\n",
              " 'космический_ADJ',\n",
              " 'истребитель_NOUN',\n",
              " 'вселенная_ADJ',\n",
              " 'звёздный_ADJ',\n",
              " 'война_NOUN',\n",
              " 'отмечаться_VERB',\n",
              " 'автор_NOUN',\n",
              " 'скульптура_NOUN',\n",
              " 'создание_NOUN',\n",
              " 'которой_PRON',\n",
              " 'уйти_VERB',\n",
              " 'около_ADP',\n",
              " 'месяц_NOUN',\n",
              " 'стать_VERB',\n",
              " 'бригада_NOUN',\n",
              " 'сухопутный_ADJ',\n",
              " 'сила_NOUN',\n",
              " 'самооборона_NOUN',\n",
              " 'япония_NOUN',\n",
              " 'изготовление_NOUN',\n",
              " 'композиция_NOUN',\n",
              " 'использоваться_VERB',\n",
              " 'бульдозер_NOUN',\n",
              " 'строительный_ADJ',\n",
              " 'лес_NOUN',\n",
              " 'скульптура_NOUN',\n",
              " 'создать_VERB',\n",
              " 'рамка_NOUN',\n",
              " 'рекламный_ADJ',\n",
              " 'кампания_NOUN',\n",
              " 'седьмой_ADJ',\n",
              " 'эпизод_NOUN',\n",
              " 'звёздный_VERB',\n",
              " 'война_NOUN',\n",
              " 'который_PRON',\n",
              " 'выйти_VERB',\n",
              " 'прокат_NOUN',\n",
              " 'декабрь_NOUN',\n",
              " 'год_NOUN',\n",
              " 'действие_NOUN',\n",
              " 'картина_NOUN',\n",
              " 'развернуться_VERB',\n",
              " 'спустя_ADP',\n",
              " 'примерно_ADV',\n",
              " 'год_NOUN',\n",
              " 'возвращение_NOUN',\n",
              " 'джедай_NOUN',\n",
              " 'последний_ADJ',\n",
              " 'хронология_NOUN',\n",
              " 'эпизод_NOUN',\n",
              " 'киносерии_NOUN',\n",
              " 'джордж_PROPN',\n",
              " 'лукас_PROPN',\n",
              " 'снежный_ADJ',\n",
              " 'фестиваль_NOUN',\n",
              " 'саппоро_ADV',\n",
              " 'впервые_ADV',\n",
              " 'пройти_VERB',\n",
              " 'год_NOUN',\n",
              " 'традиционно_ADV',\n",
              " 'скульптура_NOUN',\n",
              " 'снег_NOUN',\n",
              " 'мероприятие_NOUN',\n",
              " 'создаваться_VERB',\n",
              " 'военный_VERB',\n",
              " 'ежегодно_ADV',\n",
              " 'праздник_NOUN',\n",
              " 'приезжать_VERB',\n",
              " 'около_ADP',\n",
              " 'два_NUM',\n",
              " 'миллион_NOUN',\n",
              " 'турист_NOUN']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "X_train_pos[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f2kH0YgbDrl"
      },
      "source": [
        "## Создние эмбеддингов с Gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "vc0ldxb0YQqT"
      },
      "outputs": [],
      "source": [
        "model = Word2Vec(\n",
        "    sentences=X_train,\n",
        "    vector_size=300, # возьмем +- стандартный размер\n",
        "    window=5, #контекстное окно в 5 слов\n",
        "    min_count=10, #не берем сова встречающиеся меньше 10 раз\n",
        "    sg=1, # будем использовать stopgram\n",
        "    negative=5, # текстов довольно большое количство, поэтому используем negative sampling по 5 внеконтекстным словам\n",
        "    workers=4\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "GmRreiZxerYV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d0b4265-2655-4613-e3ee-a0a1aaace03b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n",
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20350866, 23788290)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "model.build_vocab(X_train)\n",
        "model.train(X_train, total_examples=model.corpus_count, epochs=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "0FnYIAHZeFXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "178188c9-fb05-4e00-c6f2-8fd9a5c5a6b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "россия\n"
          ]
        }
      ],
      "source": [
        "print(model.wv.doesnt_match([\"футбол\", \"хоккей\", \"россия\"]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "ClKg-Br6eFP8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "0a842269-497b-4a51-ef9c-202d996f5285"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[('ред', 0.4450737237930298),\n",
              " ('уингс', 0.423820436000824),\n",
              " ('нхл', 0.41377466917037964),\n",
              " ('рейнджерс', 0.4127780497074127),\n",
              " ('нба', 0.4094655513763428),\n",
              " ('полуфинальный', 0.3998700976371765),\n",
              " ('даллас', 0.39225339889526367),\n",
              " ('офф', 0.3904896378517151),\n",
              " ('плей', 0.38632234930992126),\n",
              " ('филадельфия', 0.3817029595375061)]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[('нью', 0.9472789764404297),\n",
              " ('йоркский', 0.5443930625915527),\n",
              " ('джерси', 0.5142751932144165),\n",
              " ('рейнджерс', 0.4043721854686737),\n",
              " ('майами', 0.3841198980808258),\n",
              " ('лос', 0.32682138681411743),\n",
              " ('ford', 0.32471179962158203),\n",
              " ('питтсбург', 0.3241317868232727),\n",
              " ('wti', 0.32367128133773804),\n",
              " ('филадельфия', 0.3163060247898102)]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(model.wv.most_similar(\"чикаго\"))\n",
        "display(model.wv.most_similar(\"йорк\"))\n",
        "\n",
        "# не то чтобы чикаго ред..но йорк действительно бывает нью"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VV0qIpOQf5iB"
      },
      "source": [
        "## Загрузка готовых эмбеддингов\n",
        "\n",
        "Из Navec попробуем взять модель news, т.к. у нас новостной корпус. Из rusvectores также возьмем модель обученную на новостях, хоть у нее и не лучшее качество на различных метриках, она не такая тяжелая как другие и в теории может давать хорошие показатели именно для домена новостей."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "tMviM66Nf5Of",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56d2bac2-b932-4608-d4ba-3eb820da976e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-14 06:52:39--  https://storage.yandexcloud.net/natasha-navec/packs/navec_news_v1_1B_250K_300d_100q.tar\n",
            "Resolving storage.yandexcloud.net (storage.yandexcloud.net)... 213.180.193.243, 2a02:6b8::1d9\n",
            "Connecting to storage.yandexcloud.net (storage.yandexcloud.net)|213.180.193.243|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26634240 (25M) [application/x-tar]\n",
            "Saving to: ‘navec_news_v1_1B_250K_300d_100q.tar’\n",
            "\n",
            "navec_news_v1_1B_25 100%[===================>]  25.40M  12.8MB/s    in 2.0s    \n",
            "\n",
            "2025-03-14 06:52:42 (12.8 MB/s) - ‘navec_news_v1_1B_250K_300d_100q.tar’ saved [26634240/26634240]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!wget https://storage.yandexcloud.net/natasha-navec/packs/navec_news_v1_1B_250K_300d_100q.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "gyWkZ4FJeFEl"
      },
      "outputs": [],
      "source": [
        "path = 'navec_news_v1_1B_250K_300d_100q.tar'\n",
        "navec = Navec.load(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Hq3GGTDGsPQQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19cdd330-9a5c-42d4-b89c-3d71e8bdd2bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('news_upos_cbow_600_2_2018.vec.gz',\n",
              " <http.client.HTTPMessage at 0x7ad247719550>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "urllib.request.urlretrieve(\n",
        "    \"https://rusvectores.org/static/models/rusvectores4/news/news_upos_cbow_600_2_2018.vec.gz\",\n",
        "    \"news_upos_cbow_600_2_2018.vec.gz\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "L3_mza6FtpBP"
      },
      "outputs": [],
      "source": [
        "rusvec_path = 'news_upos_cbow_600_2_2018.vec.gz'\n",
        "rusvec = gensim.models.KeyedVectors.load_word2vec_format(rusvec_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ZJ1cfC_Tuvvn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee080f29-5fc7-4949-9a74-81b99ddbb2fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('даллас_NOUN', 0.6791614890098572),\n",
              " ('филадельфия_NOUN', 0.6719862222671509),\n",
              " ('детройт_NOUN', 0.6665207743644714),\n",
              " ('блэкхоукс_NOUN', 0.6618371605873108),\n",
              " ('айлендерс_NOUN', 0.6555952429771423),\n",
              " ('питтсбург_NOUN', 0.639214813709259),\n",
              " ('милуоки_NOUN', 0.6332553625106812),\n",
              " ('блэкхокс_NOUN', 0.6322605013847351),\n",
              " ('бостон_NOUN', 0.627689778804779),\n",
              " ('сент-луис_NOUN', 0.6221750378608704)]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "rusvec.most_similar(positive=['чикаго_NOUN'], topn=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3PvXFo5f-Oj"
      },
      "source": [
        "## Обучение логистической регрессии\n",
        "\n",
        "Во-первых, для каждой модели сделаем отдельный класс основанный на базовом с BaseEstimator из skearn, для того чтобы было удобнее передавать эмбеддинги в пайплайн обучения.\n",
        "\n",
        "Особо параметры тут не настраиваются, но возьмем параметр аггрегации векторов слов в вектор всего текста, и параметр, отвечающий за нулевой/случайный вектор для незнакомых слов.\n",
        "\n",
        "И дальше сделаем два пайплайна - для моделей без POS-тегов и для RusVectores, в котором POS теги добавляются к признакам.\n",
        "\n",
        "___\n",
        "Второй пайплайн я так и не использовала,  т.к. были проблемы с обучением с RusVectores - при самом обучении при присвоении тегов или их удалении из слов загруженного словаря падал колаб и это ничем не фиксилось. Поэтому добавила при формировании выборок второй сет с pos-тегами X_*_pos, в итоге особого смысла это не имело, т.к. результаты у rusvec странно низкие и вообще navec всех победил...такие дела."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "kABbnqOHgDSs"
      },
      "outputs": [],
      "source": [
        "class BaseEmbedder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, aggregation='mean', oov_strategy='zeros'):\n",
        "        self.aggregation = aggregation\n",
        "        self.oov_strategy = oov_strategy\n",
        "        self.vector_size = None\n",
        "\n",
        "    def _get_vector(self, word):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def transform(self, X):\n",
        "        embeddings = []\n",
        "        for doc in X:\n",
        "            vectors = []\n",
        "            for word in doc:\n",
        "                vec = self._get_vector(word)\n",
        "                if vec is not None:\n",
        "                    vectors.append(vec)\n",
        "\n",
        "            if not vectors:\n",
        "                vectors = [np.zeros(self.vector_size)]\n",
        "\n",
        "            if self.aggregation == 'mean':\n",
        "                emb = np.mean(vectors, axis=0)\n",
        "            elif self.aggregation == 'sum':\n",
        "                emb = np.sum(vectors, axis=0)\n",
        "            elif self.aggregation == 'max':\n",
        "                emb = np.max(vectors, axis=0)\n",
        "            embeddings.append(emb)\n",
        "        return np.array(embeddings)\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "X3nvSCEfxZUM"
      },
      "outputs": [],
      "source": [
        "# класс для обработки созданных с gensim эмбеддингов\n",
        "class CustomEmbedder(BaseEmbedder):\n",
        "    def __init__(self, model, aggregation='mean', oov_strategy='zeros'):\n",
        "        super().__init__(aggregation=aggregation, oov_strategy=oov_strategy)\n",
        "        self.model = model.wv if isinstance(model, Word2Vec) else model\n",
        "        self.vector_size = self.model.vector_size\n",
        "\n",
        "    def _get_vector(self, word):\n",
        "        try:\n",
        "            return self.model.get_vector(word)\n",
        "        except KeyError:\n",
        "            if self.oov_strategy == 'zeros':\n",
        "                return np.zeros(self.vector_size)\n",
        "            elif self.oov_strategy == 'random':\n",
        "                return np.random.normal(scale=0.1, size=self.vector_size)\n",
        "            return None\n",
        "\n",
        "# класс для обработки navec эмбеддингов\n",
        "class NavecEmbedder(BaseEmbedder):\n",
        "    def __init__(self, model, aggregation='mean', oov_strategy='zeros'):\n",
        "        super().__init__(aggregation=aggregation, oov_strategy=oov_strategy)\n",
        "        self.model = model\n",
        "        self.vector_size = self._detect_vector_size()\n",
        "\n",
        "    def _detect_vector_size(self):\n",
        "        for word in ['год', 'россия', 'время']:\n",
        "            try:\n",
        "                return self.model[word].shape[0]\n",
        "            except KeyError:\n",
        "                continue\n",
        "        raise ValueError(\"\")\n",
        "\n",
        "    def _get_vector(self, word):\n",
        "        try:\n",
        "            return self.model[word]\n",
        "        except KeyError:\n",
        "            if self.oov_strategy == 'zeros':\n",
        "                return np.zeros(self.vector_size)\n",
        "            elif self.oov_strategy == 'random':\n",
        "                return np.random.normal(scale=0.1, size=self.vector_size)\n",
        "            return None\n",
        "\n",
        "# класс для обработки rusvec, который в итоге не использовался из-за добавления пос-тегов в признаки\n",
        "class RusvecEmbedder(BaseEmbedder):\n",
        "    def __init__(self, model, aggregation='mean', oov_strategy='zeros'):\n",
        "        super().__init__(aggregation=aggregation, oov_strategy=oov_strategy)\n",
        "        self.model = model.wv if isinstance(model, Word2Vec) else model\n",
        "        self.vector_size = self.model.vector_size\n",
        "        self.morph = MorphAnalyzer()\n",
        "\n",
        "    def _get_vector(self, word):\n",
        "        word_with_pos = f\"{word}_{self.morph.parse(word)[0].tag.POS}\"\n",
        "        try:\n",
        "            return self.model.get_vector(word)\n",
        "        except KeyError:\n",
        "            if self.oov_strategy == 'zeros':\n",
        "                return np.zeros(self.vector_size)\n",
        "            elif self.oov_strategy == 'random':\n",
        "                return np.random.normal(scale=0.1, size=self.vector_size)\n",
        "            return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ByCUu6FHgl0T"
      },
      "outputs": [],
      "source": [
        "# пайплайн для всех моделей\n",
        "def train_model(embedder, params, X_train, y_train):\n",
        "    pipeline = Pipeline([\n",
        "        ('embedder', embedder),\n",
        "        ('model', LogisticRegression(max_iter=1000))\n",
        "    ])\n",
        "    f1_scorer = make_scorer(f1_score, average='weighted')\n",
        "    grid = GridSearchCV(\n",
        "        pipeline,\n",
        "        params,\n",
        "        cv=4,\n",
        "        n_jobs=-1,\n",
        "        verbose=1,\n",
        "        scoring=f1_scorer\n",
        "    )\n",
        "    grid.fit(X_train, y_train)\n",
        "    return grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ixwoQcLBccKg"
      },
      "outputs": [],
      "source": [
        "# отдельный пайплайн для rusvec, тоже не использовался, но на всякий случай..можно было делать и так\n",
        "def train_rusvec_model(model, params, X_train, y_train):\n",
        "    pipeline = Pipeline([\n",
        "        ('embedder', RusvecEmbedder(model)),\n",
        "        ('model', LogisticRegression(max_iter=100))\n",
        "    ])\n",
        "    f1_scorer = make_scorer(f1_score, average='weighted')\n",
        "    grid = GridSearchCV(\n",
        "        pipeline,\n",
        "        params,\n",
        "        cv=4,\n",
        "        n_jobs=-1,\n",
        "        verbose=1,\n",
        "        scoring=make_scorer(f1_score, average='weighted')\n",
        "    )\n",
        "    grid.fit(X_train, y_train)\n",
        "    return grid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhFC1Qr2ePPM"
      },
      "source": [
        "На всякий раз еще раз уточню, что отдельный класс и пайплайн для русвек модели не использовались т.к. есть второй сет признаков с пос-тегами. И т.к. сама модель русвек сохранена в формате gensim, используем класс custom (сделанный для word2vec модели gensim) для передачи эмбеддингов в модель."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "6HENWIJQglw9"
      },
      "outputs": [],
      "source": [
        "base_params = {\n",
        "    'embedder__aggregation': ['mean', 'sum'],\n",
        "    'embedder__oov_strategy': ['zeros'],\n",
        "    'model__C': [1]\n",
        "    }\n",
        "\n",
        "gensim_params = base_params.copy()\n",
        "navec_params = base_params.copy()\n",
        "rusvec_params = base_params.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "nbak3pES-A6Q"
      },
      "outputs": [],
      "source": [
        "rusvec_params = {\n",
        "    'embedder__aggregation': ['mean'],\n",
        "    'embedder__oov_strategy': ['zeros'],\n",
        "    'model__C': [1]\n",
        "    }\n",
        "\n",
        "\n",
        "# и чем именно русвек перегружает оперативную память..\n",
        "# сделала отдельные параметры чтобы получить хоть какой-то результат на этих эмбеддингах"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "a90NQm-7xrnt"
      },
      "outputs": [],
      "source": [
        "gensim_embedder = CustomEmbedder(model=model)\n",
        "navec_embedder = NavecEmbedder(model=navec)\n",
        "rusvec_embedder = CustomEmbedder(model=rusvec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "QLjn8Gt9xrrG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fd7e875-411c-40e6-cfb2-0461bc277ece"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n"
          ]
        }
      ],
      "source": [
        "gensim_logreg = train_model(gensim_embedder, gensim_params, X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ztRhuQoIIRrv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea3a75c4-b5fb-4203-f3c1-089ddcc69025"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n"
          ]
        }
      ],
      "source": [
        "navec_logreg = train_model(navec_embedder, navec_params, X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "_6CxhTCzITW8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10ebc9ee-5c37-47ab-af06-f3a865d365e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
          ]
        }
      ],
      "source": [
        "rusvectors_logreg = train_model(rusvec_embedder, rusvec_params, X_train_pos, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "b1Xiz4wSxrwZ"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    'Word2Vec Custom': gensim_logreg,\n",
        "    'Navec': navec_logreg,\n",
        "    'RusVectores': rusvectors_logreg\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "y4S8--zW8onX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdbc1ba2-261b-4f7b-9c55-f77e4e8d816f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Word2Vec Custom ---\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   69-я параллель       0.00      0.00      0.00         3\n",
            "           Бизнес       0.00      0.00      0.00        19\n",
            "      Бывший СССР       0.72      0.51      0.60       149\n",
            "              Дом       0.86      0.62      0.72        52\n",
            "           Другое       0.00      0.00      0.00         3\n",
            "         Из жизни       0.62      0.46      0.53        76\n",
            "   Интернет и СМИ       0.67      0.53      0.59       116\n",
            "         Культура       0.83      0.87      0.85       139\n",
            "              Мир       0.70      0.86      0.77       372\n",
            "  Наука и техника       0.72      0.79      0.76       139\n",
            "      Путешествия       0.80      0.22      0.35        18\n",
            "           Россия       0.71      0.81      0.76       450\n",
            "Силовые структуры       0.62      0.15      0.25        52\n",
            "            Спорт       0.97      0.95      0.96       169\n",
            "         Ценности       1.00      0.48      0.65        23\n",
            "        Экономика       0.75      0.83      0.79       219\n",
            "\n",
            "         accuracy                           0.74      1999\n",
            "        macro avg       0.62      0.50      0.53      1999\n",
            "     weighted avg       0.74      0.74      0.73      1999\n",
            "\n",
            "\n",
            "\n",
            "--- Navec ---\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   69-я параллель       0.00      0.00      0.00         3\n",
            "           Бизнес       0.00      0.00      0.00        19\n",
            "      Бывший СССР       0.73      0.65      0.69       149\n",
            "              Дом       0.82      0.63      0.72        52\n",
            "           Другое       0.00      0.00      0.00         3\n",
            "         Из жизни       0.55      0.53      0.54        76\n",
            "   Интернет и СМИ       0.69      0.63      0.66       116\n",
            "         Культура       0.85      0.84      0.84       139\n",
            "              Мир       0.72      0.84      0.78       372\n",
            "  Наука и техника       0.77      0.78      0.78       139\n",
            "      Путешествия       0.50      0.28      0.36        18\n",
            "           Россия       0.73      0.79      0.76       450\n",
            "Силовые структуры       0.62      0.19      0.29        52\n",
            "            Спорт       0.95      0.95      0.95       169\n",
            "         Ценности       0.92      0.52      0.67        23\n",
            "        Экономика       0.75      0.81      0.78       219\n",
            "\n",
            "         accuracy                           0.75      1999\n",
            "        macro avg       0.60      0.53      0.55      1999\n",
            "     weighted avg       0.74      0.75      0.74      1999\n",
            "\n",
            "\n",
            "\n",
            "--- RusVectores ---\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "   69-я параллель       0.00      0.00      0.00         3\n",
            "           Бизнес       0.00      0.00      0.00        19\n",
            "      Бывший СССР       0.00      0.00      0.00       149\n",
            "              Дом       0.00      0.00      0.00        52\n",
            "           Другое       0.00      0.00      0.00         3\n",
            "         Из жизни       0.00      0.00      0.00        76\n",
            "   Интернет и СМИ       0.00      0.00      0.00       116\n",
            "         Культура       0.00      0.00      0.00       139\n",
            "              Мир       0.00      0.00      0.00       372\n",
            "  Наука и техника       0.00      0.00      0.00       139\n",
            "      Путешествия       0.00      0.00      0.00        18\n",
            "           Россия       0.23      1.00      0.37       450\n",
            "Силовые структуры       0.00      0.00      0.00        52\n",
            "            Спорт       0.00      0.00      0.00       169\n",
            "         Ценности       0.00      0.00      0.00        23\n",
            "        Экономика       0.00      0.00      0.00       219\n",
            "\n",
            "         accuracy                           0.23      1999\n",
            "        macro avg       0.01      0.06      0.02      1999\n",
            "     weighted avg       0.05      0.23      0.08      1999\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for name, model in models.items():\n",
        "  y_pred = model.predict(X_val)\n",
        "  print(f\"--- {name} ---\")\n",
        "  print(classification_report(y_val, y_pred, target_names=le.classes_))\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "j9VIaYXB9RuA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fbcc92c-f84d-4191-d041-240e1247f634"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'embedder__aggregation': 'mean', 'embedder__oov_strategy': 'zeros', 'model__C': 1}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "best_model = max(models.values(), key=lambda x: x.best_score_)\n",
        "print(best_model.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "yHpJIw0HOF--",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "06e80f64-65c0-4c7f-d252-b8eb5e2a6143"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=4,\n",
              "             estimator=Pipeline(steps=[('embedder',\n",
              "                                        NavecEmbedder(model=Navec(meta=Meta(id='news_v1_1B_250K_300d_100q', protocol=1), vocab=Vocab(words=[...], counts=[...]), pq=PQ(vectors=250002, dim=300, qdim=100, centroids=256, indexes=array([[176, 222, 248, ..., 244, 183, 191],\n",
              "       [215, 200, 168, ..., 120, 217,  21],\n",
              "       [ 83, 174,  54, ..., 106,  88, 251],\n",
              "       ...,\n",
              "       [133, 125, 123, ..., 124...\n",
              "        [ 0.03701574, -0.21370277, -0.05016475],\n",
              "        ...,\n",
              "        [-0.17239603,  0.18787187,  0.1649191 ],\n",
              "        [-0.0518746 , -0.14286335, -0.2335867 ],\n",
              "        [ 0.        ,  0.        ,  0.        ]]], dtype=float32))))),\n",
              "                                       ('model',\n",
              "                                        LogisticRegression(max_iter=1000))]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'embedder__aggregation': ['mean', 'sum'],\n",
              "                         'embedder__oov_strategy': ['zeros'], 'model__C': [1]},\n",
              "             scoring=make_scorer(f1_score, response_method='predict', average=weighted),\n",
              "             verbose=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4,\n",
              "             estimator=Pipeline(steps=[(&#x27;embedder&#x27;,\n",
              "                                        NavecEmbedder(model=Navec(meta=Meta(id=&#x27;news_v1_1B_250K_300d_100q&#x27;, protocol=1), vocab=Vocab(words=[...], counts=[...]), pq=PQ(vectors=250002, dim=300, qdim=100, centroids=256, indexes=array([[176, 222, 248, ..., 244, 183, 191],\n",
              "       [215, 200, 168, ..., 120, 217,  21],\n",
              "       [ 83, 174,  54, ..., 106,  88, 251],\n",
              "       ...,\n",
              "       [133, 125, 123, ..., 124...\n",
              "        [ 0.03701574, -0.21370277, -0.05016475],\n",
              "        ...,\n",
              "        [-0.17239603,  0.18787187,  0.1649191 ],\n",
              "        [-0.0518746 , -0.14286335, -0.2335867 ],\n",
              "        [ 0.        ,  0.        ,  0.        ]]], dtype=float32))))),\n",
              "                                       (&#x27;model&#x27;,\n",
              "                                        LogisticRegression(max_iter=1000))]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;embedder__aggregation&#x27;: [&#x27;mean&#x27;, &#x27;sum&#x27;],\n",
              "                         &#x27;embedder__oov_strategy&#x27;: [&#x27;zeros&#x27;], &#x27;model__C&#x27;: [1]},\n",
              "             scoring=make_scorer(f1_score, response_method=&#x27;predict&#x27;, average=weighted),\n",
              "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=4,\n",
              "             estimator=Pipeline(steps=[(&#x27;embedder&#x27;,\n",
              "                                        NavecEmbedder(model=Navec(meta=Meta(id=&#x27;news_v1_1B_250K_300d_100q&#x27;, protocol=1), vocab=Vocab(words=[...], counts=[...]), pq=PQ(vectors=250002, dim=300, qdim=100, centroids=256, indexes=array([[176, 222, 248, ..., 244, 183, 191],\n",
              "       [215, 200, 168, ..., 120, 217,  21],\n",
              "       [ 83, 174,  54, ..., 106,  88, 251],\n",
              "       ...,\n",
              "       [133, 125, 123, ..., 124...\n",
              "        [ 0.03701574, -0.21370277, -0.05016475],\n",
              "        ...,\n",
              "        [-0.17239603,  0.18787187,  0.1649191 ],\n",
              "        [-0.0518746 , -0.14286335, -0.2335867 ],\n",
              "        [ 0.        ,  0.        ,  0.        ]]], dtype=float32))))),\n",
              "                                       (&#x27;model&#x27;,\n",
              "                                        LogisticRegression(max_iter=1000))]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;embedder__aggregation&#x27;: [&#x27;mean&#x27;, &#x27;sum&#x27;],\n",
              "                         &#x27;embedder__oov_strategy&#x27;: [&#x27;zeros&#x27;], &#x27;model__C&#x27;: [1]},\n",
              "             scoring=make_scorer(f1_score, response_method=&#x27;predict&#x27;, average=weighted),\n",
              "             verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;embedder&#x27;,\n",
              "                 NavecEmbedder(model=Navec(meta=Meta(id=&#x27;news_v1_1B_250K_300d_100q&#x27;, protocol=1), vocab=Vocab(words=[...], counts=[...]), pq=PQ(vectors=250002, dim=300, qdim=100, centroids=256, indexes=array([[176, 222, 248, ..., 244, 183, 191],\n",
              "       [215, 200, 168, ..., 120, 217,  21],\n",
              "       [ 83, 174,  54, ..., 106,  88, 251],\n",
              "       ...,\n",
              "       [133, 125, 123, ..., 124,  94,  24],\n",
              "       [183,  49, 180, ..., 151,...\n",
              "        [ 0.40001723, -0.43998858,  0.17731333],\n",
              "        [-0.28567192, -0.07258819, -0.52291226],\n",
              "        [ 0.        ,  0.        ,  0.        ]],\n",
              "\n",
              "       [[ 0.17092301, -0.30629456, -0.07775806],\n",
              "        [-0.02551726,  0.34224212,  1.0160226 ],\n",
              "        [ 0.03701574, -0.21370277, -0.05016475],\n",
              "        ...,\n",
              "        [-0.17239603,  0.18787187,  0.1649191 ],\n",
              "        [-0.0518746 , -0.14286335, -0.2335867 ],\n",
              "        [ 0.        ,  0.        ,  0.        ]]], dtype=float32))))),\n",
              "                (&#x27;model&#x27;, LogisticRegression(C=1, max_iter=1000))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>NavecEmbedder</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>NavecEmbedder(model=Navec(meta=Meta(id=&#x27;news_v1_1B_250K_300d_100q&#x27;, protocol=1), vocab=Vocab(words=[...], counts=[...]), pq=PQ(vectors=250002, dim=300, qdim=100, centroids=256, indexes=array([[176, 222, 248, ..., 244, 183, 191],\n",
              "       [215, 200, 168, ..., 120, 217,  21],\n",
              "       [ 83, 174,  54, ..., 106,  88, 251],\n",
              "       ...,\n",
              "       [133, 125, 123, ..., 124,  94,  24],\n",
              "       [183,  49, 180, ..., 151, 167,  68],\n",
              "       [255, 255, 255, ..., 255...\n",
              "        [-0.263664  , -0.31701726,  0.86469847],\n",
              "        [-0.4636477 ,  0.34382322,  0.8587696 ],\n",
              "        ...,\n",
              "        [ 0.40001723, -0.43998858,  0.17731333],\n",
              "        [-0.28567192, -0.07258819, -0.52291226],\n",
              "        [ 0.        ,  0.        ,  0.        ]],\n",
              "\n",
              "       [[ 0.17092301, -0.30629456, -0.07775806],\n",
              "        [-0.02551726,  0.34224212,  1.0160226 ],\n",
              "        [ 0.03701574, -0.21370277, -0.05016475],\n",
              "        ...,\n",
              "        [-0.17239603,  0.18787187,  0.1649191 ],\n",
              "        [-0.0518746 , -0.14286335, -0.2335867 ],\n",
              "        [ 0.        ,  0.        ,  0.        ]]], dtype=float32))))</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=1, max_iter=1000)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "best_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wMg-qrBgmQG"
      },
      "source": [
        "## Добавление весов TF-IDF для лучших эмбеддингов\n",
        "\n",
        "Т.к. модель показала лучший результат именно с эмбеддингами Navec сделаем еще один класс основанный на NavecEmbedder и добавим туда аггрегацию эмбеддингов слов для всего текста с усреднением по весам TF-IDF.\n",
        "\n",
        "И сравним как это будет влиять на качество модели по сравнению с простой аггрегацией по сумме/усреднению в базовом классе."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "class TfidfNavecEmbedder(NavecEmbedder):\n",
        "    def __init__(self, model, oov_strategy='zeros', min_df=1, max_df=1.0):\n",
        "        super().__init__(model=model, aggregation='mean', oov_strategy=oov_strategy)\n",
        "        self.min_df = min_df\n",
        "        self.max_df = max_df\n",
        "        self.tfidf_vectorizer = TfidfVectorizer(\n",
        "            min_df=min_df,\n",
        "            max_df=max_df,\n",
        "            tokenizer=lambda x: x,  # т.к. у нас уже все тексты разбиты на токены просто передаем списки\n",
        "            preprocessor=lambda x: x,\n",
        "            token_pattern=None\n",
        "        )\n",
        "        self.vocabulary_ = None\n",
        "        self.idf = None\n",
        "        self.word_to_tfidf_index = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.tfidf_vectorizer.fit(X)\n",
        "        self.vocabulary_ = self.tfidf_vectorizer.vocabulary_\n",
        "        self.idf = self.tfidf_vectorizer.idf_\n",
        "        self.word_to_tfidf_index = {word: idx for word, idx in self.vocabulary_.items()}\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        tfidf_matrix = self.tfidf_vectorizer.transform(X)\n",
        "        embeddings = []\n",
        "        for i, doc in enumerate(X):\n",
        "            doc_tfidf = tfidf_matrix[i].toarray().flatten()\n",
        "            doc_embedding = np.zeros(self.vector_size)\n",
        "            total_weight = 0\n",
        "            for word in doc:\n",
        "                vec = self._get_vector(word)\n",
        "                if vec is None:\n",
        "                    continue\n",
        "                if word in self.word_to_tfidf_index:\n",
        "                    idx = self.word_to_tfidf_index[word]\n",
        "                    weight = doc_tfidf[idx]\n",
        "                    doc_embedding += vec * weight\n",
        "                    total_weight += weight\n",
        "\n",
        "            if total_weight > 0:\n",
        "                doc_embedding /= total_weight\n",
        "\n",
        "            embeddings.append(doc_embedding)\n",
        "        return np.array(embeddings)"
      ],
      "metadata": {
        "id": "tQCKooXna6Nb"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "s875RPXJgz1F"
      },
      "outputs": [],
      "source": [
        "tfidf_embedder = TfidfNavecEmbedder(model=navec)\n",
        "\n",
        "tfidf_params = {\n",
        "    'embedder__oov_strategy': ['zeros'],\n",
        "    'embedder__min_df': [3, 5],\n",
        "    'embedder__max_df': [0.9, 0.95, 0.99],\n",
        "    'model__C': [1]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "tQl5vYndgwgP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe44827a-e389-420b-f32f-be60d093610d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n"
          ]
        }
      ],
      "source": [
        "tfidf_grid = train_model(tfidf_embedder, tfidf_params, X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "3UUx1Et0g19E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4f45358-30b1-4f24-996e-6f67c1df302e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'embedder__max_df': 0.9, 'embedder__min_df': 3, 'embedder__oov_strategy': 'zeros', 'model__C': 1}\n"
          ]
        }
      ],
      "source": [
        "best_model_nvtf = tfidf_grid.best_estimator_\n",
        "best_params = tfidf_grid.best_params_\n",
        "print(\"Best parameters:\", best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "qCsU-tJAvKv_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57449831-f14b-4b9a-ee62-63a07601b350"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val F1 score navec and tf-idf: 0.7119\n"
          ]
        }
      ],
      "source": [
        "y_pred = best_model_nvtf.predict(X_val)\n",
        "print(f\"Val F1 score navec and tf-idf: {f1_score(y_val, y_pred, average='weighted'):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Интересно, простое усреднение сработало лучше, чем усреднение с tf-idf весами.."
      ],
      "metadata": {
        "id": "6N6hGZrLWMME"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPD_Hjqeg-a1"
      },
      "source": [
        "## Финальная оценка моделей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "JaTWoCMlhAzf"
      },
      "outputs": [],
      "source": [
        "y_pred_custom = gensim_logreg.predict(X_test)\n",
        "y_pred_navec = navec_logreg.predict(X_test)\n",
        "y_pred_rusvec = rusvectors_logreg.predict(X_test_pos)\n",
        "y_pred_navectfidf = best_model_nvtf.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "PnT2uY-zwq3i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a113959f-d233-4447-aaf2-56d22c2ae2ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test F1 score w2v custom embeddings: 0.7336\n",
            "Test F1 score navec: 0.7500\n",
            "Test F1 score rusvec: 0.0827\n",
            "Test F1 score navec and tf-idf weights: 0.7296\n"
          ]
        }
      ],
      "source": [
        "print(f\"Test F1 score w2v custom embeddings: {f1_score(y_test, y_pred_custom, average='weighted'):.4f}\")\n",
        "print(f\"Test F1 score navec: {f1_score(y_test, y_pred_navec, average='weighted'):.4f}\")\n",
        "print(f\"Test F1 score rusvec: {f1_score(y_val, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Test F1 score navec and tf-idf weights: {f1_score(y_test, y_pred_navectfidf, average='weighted'):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В итоге лучше всех оказалась модель с navec с простым усреднением векторов для получения вектора текста. Если бы тексов было больше чем 10к то метрика явно была бы гораздо лучше, но пока что так как есть, в будущем надо попробовать прогнать эту тетрадку на чем-то более мощном и предсказуемом чем колаб."
      ],
      "metadata": {
        "id": "ViJ_Xo3Ffgjo"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}